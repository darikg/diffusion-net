{
 "cells": [
  {
   "cell_type": "code",
   "id": "00a7bccf-59c3-46a7-bc46-539493bb0b64",
   "metadata": {},
   "source": [
    "# pm.render()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a07bec17-f1e8-4458-90ef-bcf5c2797b09",
   "metadata": {},
   "source": [
    "import pyvista as pv\n",
    "from seagullmesh import Mesh3\n",
    "import numpy as np\n",
    "import pymeshfix\n",
    "from ga_population import *\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "pm = ProbeMesh.load(\n",
    "    mesh_file=r\"D:\\mesh_extract_work\\robin\\robin_animated_v4_mesh_extraction.ply\",\n",
    "    index='robin_animated_v4_orig_Main.png',\n",
    "    img_file=r\"C:\\corpus2_temp\\robin_animated_v4_orig_Main.png\",\n",
    "    cam_pos=(-31.297409057617188, -16.788650512695312, 8.073495864868164),\n",
    "    tgt_pos=(-0.15069210529327393, -2.3357276916503906, 4.40774393081665),\n",
    "    repair=False,\n",
    "    fill_holes=False,\n",
    "    cache=True,\n",
    "    recache=False,\n",
    "    wrap=True,\n",
    "    relative_alpha=600,\n",
    "    relative_offset=1000,\n",
    "    simplify_n_faces=5000,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pm.render()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eda474c5-5ab2-42f0-a258-497d808ff4ba",
   "metadata": {},
   "source": [
    "mesh_file = Path(r\"D:\\mesh_extract_work\\robin\\robin_animated_v4_mesh_extraction.ply\")\n",
    "pv_mesh = pv.read(mesh_file).triangulate().clean()\n",
    "pv_mesh.plot(show_edges=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "162fad7f-fdac-4587-a05b-2354291fc00f",
   "metadata": {},
   "source": [
    "sm_mesh = Mesh3.from_alpha_wrapping(pv_mesh.points, faces=pv_mesh.regular_faces, relative_alpha=600, relative_offset=1000)\n",
    "sm_mesh.to_pyvista().plot(show_edges=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f7b9213-29fa-4d08-b430-9f396a8e60ac",
   "metadata": {},
   "source": [
    "sm_mesh2 = sm_mesh.copy()\n",
    "sm_mesh2.edge_collapse('face', 5000)\n",
    "sm_mesh2.to_pyvista().plot(show_edges=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51d6a068-bc35-4716-af5c-be89500ebb8d",
   "metadata": {},
   "source": [
    "# Can't fix triangle orientation, the repair throws out most of the mesh\n",
    "\n",
    "pm = ProbeMesh.load(\n",
    "    mesh_file=r\"D:\\mesh_extract_work\\nespr4esso\\Coffee_Machine_v3_mesh_extraction.ply\",\n",
    "    index='Coffee_Machine_v3_orig.png',\n",
    "    img_file=r\"C:\\corpus2_temp\\Coffee_Machine_v3_orig.png\",\n",
    "    cam_pos=(0.4897646903991699, 1.369809627532959, 1.192300796508789),\n",
    "    tgt_pos=(0.039121244102716446, 0.007926076650619507, 0.2581562101840973),\n",
    "    repair=False,\n",
    "    fill_holes=False,\n",
    "    cache=True,\n",
    "    recache=True,\n",
    "    wrap=True,\n",
    "    relative_alpha=600,\n",
    "    relative_offset=1000,\n",
    "    simplify_n_faces=3000,\n",
    ")\n",
    "pm.render()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b7ca45d4-5927-457a-8fb8-4f04890827a7",
   "metadata": {},
   "source": [
    "models = SourceModels.current_trained()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7297aca5-dd18-4816-bcae-31eed95a46ed",
   "metadata": {},
   "source": [
    "# models = self = SourceModels.current_trained()\n",
    "# cp_vertex_weights = models.get_weights(cp_pms, expt_kwargs=dict(outputs_at='vertices'))\n",
    "# torch.save(cp_vertex_weights, 'temp_weights.pt')\n",
    "\n",
    "cp_vertex_weights = torch.load('temp_weights.pt')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d8189e4-e836-4e4a-ac1b-ae235d3c971a",
   "metadata": {},
   "source": [
    "# # PRINCIPLE COMPONENTS - PLOT SEPARATE\n",
    "\n",
    "# for pm, weights in zip(cp_pms, cp_vertex_weights):\n",
    "#     pm.plot_weights(weights=weights.pca(), shape=(1, 3), window_size=(1500, 500), scalar_bar=True, titles=['PC1', 'PC2', 'PC3'], render=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "946e06d6-f2f6-48c4-83d4-f51872163ddd",
   "metadata": {},
   "source": [
    "# # PRINCIPLE COMPONENTS - PLOT RGB\n",
    "\n",
    "# plotter = pv.Plotter(shape=(1, 3))\n",
    "# for i, (pm, weights) in enumerate(zip(cp_pms, cp_vertex_weights)):\n",
    "#     plotter.subplot(0, i)\n",
    "#     plotter.camera = pm.camera\n",
    "#     plotter.add_mesh(pm.mesh, scalars=weights.pca(), rgb=True)\n",
    "# plotter.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "788da6d2-d120-4621-9363-318e5b0f8349",
   "metadata": {},
   "source": [
    "# cp_pm_preds = models.get_predictions(pms)\n",
    "# torch.save(cp_pm_preds, 'temp_preds.pt')\n",
    "\n",
    "cp_pm_preds = torch.load('temp_preds.pt')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46b0ed82-9355-4c6e-94c5-895f438b3698",
   "metadata": {},
   "source": [
    "# cp_responses = models.cp_responses.loc[preds.index]\n",
    "# cp_responses.to_hdf('cp_responses.hdf', key='cp_responses')\n",
    "\n",
    "cp_responses = pd.read_hdf('cp_responses.hdf', key='cp_responses')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "491651f6-bd73-4208-974d-c5495096bbb7",
   "metadata": {},
   "source": [
    "rvals = np.zeros(cp_pm_preds.shape[1])\n",
    "for i, (unit_idx, r_mesh) in enumerate(cp_pm_preds.items()):\n",
    "    r_corpus = cp_responses.loc[:, unit_idx]\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore')\n",
    "        rvals[i] = pearsonr(r_mesh, r_corpus).statistic\n",
    "rvals[np.isnan(rvals)] = -1\n",
    "best_units = cp_responses.columns[np.argsort(rvals)[::-1]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "471c2483-cc11-4d20-b273-d35e342a8ea1",
   "metadata": {},
   "source": [
    "def load_unit_best(model_idx: int, channel_idx: int, n_best: int):\n",
    "    model = models[model_idx]\n",
    "    meta = model.reader.metadata\n",
    "    scenes, responses, weights, fit_fns = meta.load_data(weights=meta.weight_error)\n",
    "    # cp_weights = pm_weights[model_idx]\n",
    "    channel = meta.channel[channel_idx]\n",
    "    unit_responses = responses.iloc[:, channel_idx].sort_values(ascending=False)\n",
    "    unit_best_scenes = unit_responses.index[:n_best]\n",
    "\n",
    "    # Load the meshes\n",
    "    ga_pms = list(ProbeMesh.load_ga_stim(meta.opts.data_dir, scenes.loc[unit_best_scenes]))\n",
    "\n",
    "    # Present the meshes to the network to get vertex weights\n",
    "    dataset = GaDataset(\n",
    "        df=scenes.loc[unit_best_scenes],  # type: ignore\n",
    "        responses=responses.loc[unit_best_scenes],  # type: ignore\n",
    "        root_dir=meta.opts.data_file.parent,\n",
    "        k_eig=meta.k_eig,\n",
    "        op_cache_dir=meta.opts.data_dir / 'op_cache',\n",
    "        file_mode=meta.opts.mesh_file_mode,\n",
    "        weights=meta.weight_error,\n",
    "        use_visible=meta.use_visible,\n",
    "        use_color=meta.use_color,\n",
    "        norm_verts=meta.norm_verts,\n",
    "        features=meta.input_features,\n",
    "        augment=None,\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, shuffle=False, batch_size=None)\n",
    "    expt = model.reader.experiment(outputs_at='vertices')\n",
    "    assert expt.model.outputs_at == 'vertices'\n",
    "    _ga_obs, ga_weights = expt.predict(dataloader, agg_fn=lambda x: x)\n",
    "    ga_weights = [VertexWeights(weights=w) for w in ga_weights]\n",
    "\n",
    "    return ga_pms, ga_weights"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3d065ac3-680b-4dcb-8751-500e374f196f",
   "metadata": {},
   "source": [
    "def plot_images(pms: list[ProbeMesh], vertex_weights: list[VertexWeights], channel_idx: int, img_sz=(5, 5), title=None):\n",
    "    img_sz = np.array(img_sz)\n",
    "    n = len(pms)\n",
    "    fig, axs = plt.subplots(2, n, figsize=(img_sz[0] * n, img_sz[1] * 2), squeeze=False)\n",
    "    for axs_i, pm, vw in zip(axs.T, pms, vertex_weights):\n",
    "        rendered_weights = pm.render(\n",
    "            weights=vw.weights[:, channel_idx], \n",
    "            ground=False, \n",
    "            show_scalar_bar=False, \n",
    "            window_size=(1024, 1024),\n",
    "        )\n",
    "        rendered_image = PIL.Image.open(pm.img_file)\n",
    "        \n",
    "        for ax, img in zip(axs_i, (rendered_weights, rendered_image)):\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "\n",
    "        if title:\n",
    "            axs_i[1].set_title(title.format(index=pm.index))\n",
    "            \n",
    "    fig.tight_layout()\n",
    "    return fig"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "feb85c25-c443-44d4-b379-d8309975124f",
   "metadata": {},
   "source": [
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "# from tqdm.autonotebook import tqdm\n",
    "\n",
    "# img_sz = (3, 3)\n",
    "# n_best_units = 10\n",
    "# n_best_ga_stim = 5\n",
    "\n",
    "# with PdfPages('synthetic_mesh_model_predictions2.pdf') as pdf:\n",
    "#     for model_idx, channel_idx in tqdm(best_units[:n_best_units]):\n",
    "#         model = models[model_idx]\n",
    "#         run_name = Path(model.trained_file).parts[2]\n",
    "#         channel = model.reader.metadata.channel[channel_idx]\n",
    "#         model_title = f'{run_name} ch{channel}'\n",
    "    \n",
    "#         ga_pms, ga_vertex_weights = load_unit_best(model_idx=model_idx, channel_idx=channel_idx, n_best=n_best_ga_stim)\n",
    "#         fig = plot_images(ga_pms, ga_vertex_weights, channel_idx=channel_idx, img_sz=img_sz, title='Scene {index}')\n",
    "#         fig.suptitle(model_title)\n",
    "#         pdf.savefig(fig)\n",
    "#         plt.close(fig)\n",
    "\n",
    "#         idx = cp_responses.columns == (model_idx, channel_idx)\n",
    "#         this_unit_vws = [VertexWeights(vw.weights[:, idx]) for vw in cp_vertex_weights]\n",
    "#         fig = plot_images(cp_pms, this_unit_vws, channel_idx=0, img_sz=(3, 3))\n",
    "#         # fig.suptitle(model_title)\n",
    "#         pdf.savefig(fig)\n",
    "#         plt.close(fig)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "27e6bae1-cc8b-4395-9ccf-83938e1c9dc4",
   "metadata": {},
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "img_sz = (3, 3)\n",
    "n_best_units = 10\n",
    "n_best_ga_stim = 5\n",
    "\n",
    "with ZipFile('synthetic_mesh_model_predictions.zip', 'w') as zip_file:\n",
    "    for model_idx, channel_idx in tqdm(best_units[:n_best_units]):\n",
    "        model = models[model_idx]\n",
    "        run_name = Path(model.trained_file).parts[2]\n",
    "        channel = model.reader.metadata.channel[channel_idx]\n",
    "        model_title = f'{run_name} ch{channel}'\n",
    "    \n",
    "        ga_pms, ga_vertex_weights = load_unit_best(model_idx=model_idx, channel_idx=channel_idx, n_best=n_best_ga_stim)\n",
    "        fig = plot_images(ga_pms, ga_vertex_weights, channel_idx=channel_idx, img_sz=img_sz, title='Scene {index}')\n",
    "        fig.suptitle(model_title)\n",
    "        filename = Path(f'{model_title} - ga.png')\n",
    "        fig.savefig(filename)\n",
    "        zip_file.write(filename)\n",
    "        filename.unlink()\n",
    "\n",
    "        idx = cp_responses.columns == (model_idx, channel_idx)\n",
    "        this_unit_vws = [VertexWeights(vw.weights[:, idx]) for vw in cp_vertex_weights]\n",
    "        fig = plot_images(cp_pms, this_unit_vws, channel_idx=0, img_sz=(3, 3))\n",
    "        # fig.suptitle(model_title)\n",
    "        filename = Path(f'{model_title} - corpus.png')\n",
    "        fig.savefig(filename)\n",
    "        zip_file.write(filename)\n",
    "        filename.unlink()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
