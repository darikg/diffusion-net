{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70413449-93ad-4268-8d6d-7e6b3fc162f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\dg\\\\Documents\\\\python\\\\diffusion-net\\\\experiments\\\\regression_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd2d4ea4-7578-4cdf-821d-b5d18c4106b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc92ef38-b88e-4fdf-89b5-52564f24bd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dg\\.conda\\envs\\diffnet4\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from ga_population import *\n",
    "\n",
    "paths = {\n",
    "    51: Path(r\"D:\\resynth\\run_51_52\\run00051_resynth\\2025-09-16-15-34-44\\opts_and_metadata.pt\"),\n",
    "    42: Path(r\"D:\\resynth\\run_42_43\\run00042_resynth\\2025-09-11-16-14-13\\opts_and_metadata.pt\"),\n",
    "    48: Path(r\"D:\\resynth\\run_48_49\\run00048_resynth\\2025-09-12-13-05-14\\opts_and_metadata.pt\"),\n",
    "    38: Path(r\"D:\\resynth\\run_38_39\\run00038_resynth\\2025-09-13-10-59-36\\opts_and_metadata.pt\"),\n",
    "    20: Path(r\"D:\\resynth\\run_20_21\\run00020_resynth\\2025-09-14-15-06-07\\opts_and_metadata.pt\"),\n",
    "     9: Path(r\"D:\\resynth\\run_09_10\\run00009_resynth\\2025-09-15-10-17-13\\opts_and_metadata.pt\"),\n",
    "}\n",
    "readers = {run_id: Readers.from_file(f) for run_id, f in paths.items()}\n",
    "\n",
    "def get_readers(visible_mode: UseVisibleMode | None):\n",
    "    out = dict()\n",
    "    tgt = str(visible_mode)\n",
    "    for run_id, rs in readers.items():\n",
    "        idx = next(i for i, v in rs.hparams.use_visible.items() if str(v) == tgt)\n",
    "        out[run_id] = rs[idx]\n",
    "    return out\n",
    "\n",
    "def get_src_models(visible_mode: UseVisibleMode | None):\n",
    "    readers = get_readers(visible_mode)\n",
    "    return {\n",
    "        run_id: SourceModel.from_reader(reader, cp_data_file=Path(SourceModels.cp_data_files(run_id)))\n",
    "        for run_id, reader in readers.items()\n",
    "    }\n",
    "\n",
    "# _sms = get_src_models(UseVisibleMode(False, False))\n",
    "_sms = get_src_models(None)\n",
    "sms = SourceModels(list(_sms.values()))\n",
    "\n",
    "pms = [p.cached() for p in ProbeMeshSpec.defined()]\n",
    "\n",
    "recache = False\n",
    "cp_pm_preds = sms.corpus_probe_mesh_preds(pms=pms, cache_file='cp_pm_preds.hdf', recache=recache)\n",
    "cp_responses = sms.corpus_observed_responses(cp_pm_preds=cp_pm_preds, cache_file='cpm_responses.hdf', recache=recache)\n",
    "\n",
    "# vertex weights is a n_stim list of VertexWeights, wehere VertexWeights.weights is (n_vertices, n_channels_total)\n",
    "# cp_vertex_weights = sms.get_weights(pms, expt_kwargs=dict(outputs_at='vertices'))\n",
    "# torch.save(cp_vertex_weights, 'cp_vertex_weights.pt')\n",
    "cp_vertex_weights = torch.load('cp_vertex_weights.pt')\n",
    "\n",
    "drop = [\n",
    "    'Barcelona Door Handle Brass_wip_v3_orig.png',\n",
    "    'JF0N2N0A_Chipmunk_FindFood_v4_orig_Main.png',\n",
    "    'door_knob_v3_orig.png',\n",
    "    'Door Handle 015 v3_orig.png',\n",
    "    'Muuto_Tip_Table_Light_v3_orig.png',\n",
    "    'FLOOR_LAMP_02_v3_orig.png',\n",
    "    'FLOOR_LAMP_03_v3_orig.png',\n",
    "    'liquor_bottles_v4_orig_Ballantine.png',\n",
    "    'liquor_bottles_v4_orig_Bombay.png',\n",
    "    'Vintage_Ring_Shaped_Door_Knocker_v3_orig.png',\n",
    "    'Lamp_v3_orig.png',\n",
    "    'Coffee_Machine_v3_orig.png',\n",
    "    'Lemon_v3_orig.png',\n",
    "    'Mouse with Mousepad_v3_orig.png',\n",
    "]\n",
    "keep = [i for i, pm in enumerate(pms) if pm.index not in drop]\n",
    "pms = np.array(pms)[keep].tolist()\n",
    "cp_vertex_weights = np.array(cp_vertex_weights)[keep].tolist()\n",
    "cp_responses_vr = cp_responses.iloc[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af824269-ea74-462f-84cd-6b831d35c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0270bf9d-6b3c-4425-be79-3c35d5050213",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e0ac5f2-5431-4fb1-ade7-b96cfd0b504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def _scatter(ax, obs, preds, ttl):\n",
    "    ax.plot(obs, preds, 'k.')\n",
    "    ax.plot(obs, preds, 'k.')\n",
    "    r = pearsonr(obs, preds).statistic\n",
    "    ax.set_title(f'{ttl} (r={r:.2f})')\n",
    "    ax.set_xlabel('Observed response')\n",
    "    ax.set_ylabel('Predicted responses')\n",
    "    ax.axis('square')\n",
    "\n",
    "\n",
    "def scatter_plots(reader, channel, global_ch_idx, fig=None, ttl=''):\n",
    "    if fig:\n",
    "        axs = fig.subplots(1, 3)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    sd = reader.scatter_data\n",
    "\n",
    "    axs[0].axis('off')\n",
    "    if ttl:\n",
    "        axs[0].set_title(ttl)\n",
    "    \n",
    "    _scatter(axs[1], *sd.loc(scene_ids=reader.train_scenes, channel=channel), ttl='Train GA')\n",
    "    _scatter(axs[2], *sd.loc(scene_ids=reader.test_scenes, channel=channel), ttl='Test GA')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_single_channel_vertex_weights(\n",
    "        pms: list[ProbeMesh],\n",
    "        vertex_weights: list[VertexWeights],\n",
    "        channel_idx: int,\n",
    "        img_sz=(5, 5),\n",
    "        grid_sz=None,\n",
    "        fig=None,\n",
    "        weights_clim_pctile=(1, 99),\n",
    "):\n",
    "    n_stim = len(pms)\n",
    "    assert len(vertex_weights) == n_stim\n",
    "    if grid_sz is None:\n",
    "        _n = int(np.ceil(np.sqrt(n_stim)))\n",
    "        grid_sz = (_n, _n)\n",
    "\n",
    "    nr, nc = grid_sz\n",
    "    img_sz = np.array(img_sz)\n",
    "\n",
    "    if fig:\n",
    "        axs = fig.subplots(nr, nc)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(nr, nc, figsize=(img_sz[0] * nc, img_sz[1] * nr), squeeze=False)\n",
    "\n",
    "    axs = axs.reshape(-1)\n",
    "\n",
    "    for pm, vw, ax in zip(pms, vertex_weights, axs):\n",
    "        rendered_weights = pm.render(\n",
    "            weights=vw.weights[:, channel_idx],\n",
    "            ground=False,\n",
    "            show_scalar_bar=False,\n",
    "            window_size=(1024, 1024),\n",
    "            weights_clim_pctile=weights_clim_pctile,\n",
    "        )\n",
    "        ax.imshow(rendered_weights)\n",
    "        ax.axis('off')\n",
    "\n",
    "    for ax in axs[n_stim:]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    return fig\n",
    "\n",
    "def plot_single_channel_renders(\n",
    "        pms: list[ProbeMesh],\n",
    "        channel_idx: int,\n",
    "        img_sz=(5, 5),\n",
    "        grid_sz=None,\n",
    "        fig=None,\n",
    "        responses=None,\n",
    "        preds=None,\n",
    "):\n",
    "    n_stim = len(pms)\n",
    "    if grid_sz is None:\n",
    "        _n = int(np.ceil(np.sqrt(n_stim)))\n",
    "        grid_sz = (_n, _n)\n",
    "\n",
    "    nr, nc = grid_sz\n",
    "    img_sz = np.array(img_sz)\n",
    "\n",
    "    if fig:\n",
    "        axs = fig.subplots(nr, nc)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(nr, nc, figsize=(img_sz[0] * nc, img_sz[1] * nr), squeeze=False)\n",
    "\n",
    "    axs = axs.reshape(-1)\n",
    "\n",
    "    if responses is None:\n",
    "        responses = [None for _ in pms]\n",
    "    if preds is None:\n",
    "        preds = [None for _ in pms]\n",
    "\n",
    "    bar_w = 0.025\n",
    "    for pm, ax, r, p in zip(pms, axs, responses, preds):\n",
    "        ax.imshow(pm.img, extent=(0, 1, 0, -1))\n",
    "        if r is not None:\n",
    "            ax.add_patch(Rectangle((0, 0), bar_w, -r, facecolor='red'))\n",
    "        if p is not None:\n",
    "            ax.add_patch(Rectangle((bar_w, 0,), bar_w, -p, facecolor='blue'))\n",
    "                         \n",
    "        ax.axis('off')\n",
    "        \n",
    "\n",
    "    for ax in axs[n_stim:]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    return fig\n",
    "\n",
    "def load_unit_best(model, channel_idx: int, n_best: int):\n",
    "    meta = model.reader.metadata\n",
    "    scenes, responses, weights, fit_fns = meta.load_data(weights=meta.weight_error)\n",
    "    channel = meta.channel[channel_idx]\n",
    "    unit_responses = responses.iloc[:, channel_idx].sort_values(ascending=False)\n",
    "    unit_best_scenes = unit_responses.index[:n_best]\n",
    "\n",
    "    # Load the meshes\n",
    "    ga_pms = list(ProbeMesh.load_ga_stim(meta.opts.data_dir, scenes.loc[unit_best_scenes]))\n",
    "\n",
    "    # Present the meshes to the network to get vertex weights\n",
    "    dataset = GaDataset(\n",
    "        df=scenes.loc[unit_best_scenes],  # type: ignore\n",
    "        responses=responses.loc[unit_best_scenes],  # type: ignore\n",
    "        root_dir=meta.opts.data_file.parent,\n",
    "        k_eig=meta.k_eig,\n",
    "        op_cache_dir=meta.opts.data_dir / 'op_cache',\n",
    "        file_mode=meta.opts.mesh_file_mode,\n",
    "        weights=meta.weight_error,\n",
    "        use_visible=meta.use_visible,\n",
    "        use_color=meta.use_color,\n",
    "        norm_verts=meta.norm_verts,\n",
    "        features=meta.input_features,\n",
    "        augment=None,\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, shuffle=False, batch_size=None)\n",
    "    expt = model.reader.experiment(outputs_at='global_mean')\n",
    "    _, ga_preds = expt.predict(dataloader, agg_fn=np.stack)\n",
    "    ga_preds = ga_preds[:, channel_idx]\n",
    "    \n",
    "    expt.model.outputs_at = 'vertices'\n",
    "    _ga_obs, ga_weights = expt.predict(dataloader, agg_fn=lambda x: x)\n",
    "    ga_weights = [VertexWeights(weights=w) for w in ga_weights]\n",
    "\n",
    "    return ga_pms, ga_weights, unit_responses.values[:n_best], ga_preds\n",
    "\n",
    "# def load_unit_best(model, channel_idx: int, n_best: int):\n",
    "#     meta = model.reader.metadata\n",
    "#     scenes, responses, weights, fit_fns = meta.load_data(weights=meta.weight_error)\n",
    "#     channel = meta.channel[channel_idx]\n",
    "\n",
    "#     n_sample = n_best * 4\n",
    "#     unit_responses = responses.iloc[:, channel_idx].sort_values(ascending=False)\n",
    "#     ga_resps = unit_responses.values[:n_sample]\n",
    "#     unit_best_scenes = unit_responses.index[:n_sample]\n",
    "\n",
    "#     # Load the meshes\n",
    "#     ga_pms = list(ProbeMesh.load_ga_stim(meta.opts.data_dir, scenes.loc[unit_best_scenes]))\n",
    "\n",
    "#     # Present the meshes to the network to get vertex weights\n",
    "#     dataset = GaDataset(\n",
    "#         df=scenes.loc[unit_best_scenes],  # type: ignore\n",
    "#         responses=responses.loc[unit_best_scenes],  # type: ignore\n",
    "#         root_dir=meta.opts.data_file.parent,\n",
    "#         k_eig=meta.k_eig,\n",
    "#         op_cache_dir=meta.opts.data_dir / 'op_cache',\n",
    "#         file_mode=meta.opts.mesh_file_mode,\n",
    "#         weights=meta.weight_error,\n",
    "#         use_visible=meta.use_visible,\n",
    "#         use_color=meta.use_color,\n",
    "#         norm_verts=meta.norm_verts,\n",
    "#         features=meta.input_features,\n",
    "#         augment=None,\n",
    "#     )\n",
    "#     dataloader = DataLoader(dataset, shuffle=False, batch_size=None)\n",
    "#     expt = model.reader.experiment(outputs_at='global_mean')\n",
    "#     _, ga_preds = expt.predict(dataloader, agg_fn=np.stack)\n",
    "#     ga_preds = ga_preds[:, channel_idx]\n",
    "    \n",
    "#     expt.model.outputs_at = 'vertices'\n",
    "#     _ga_obs, ga_weights = expt.predict(dataloader, agg_fn=lambda x: x)\n",
    "#     ga_weights = [VertexWeights(weights=w) for w in ga_weights]\n",
    "\n",
    "#     objective = ga_resps - np.abs(ga_resps - ga_preds)\n",
    "#     idx = np.argsort(objective)[-n_best:][::-1]\n",
    "\n",
    "#     ga_pms = [ga_pms[i] for i in idx]\n",
    "#     ga_weights = [ga_weights[i] for i in idx]\n",
    "#     ga_resps = ga_resps[idx]\n",
    "#     ga_preds = ga_preds[idx]\n",
    "\n",
    "#     return ga_pms, ga_weights, ga_resps, ga_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a76e9d8f-a99f-40fe-b3b2-6c420437dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_channels = {\n",
    "    9: [0, 2, 23, 31],\n",
    "    20: [3, 30, 31],\n",
    "    38: [13, 14, 17, 18, 29, 31],\n",
    "    42: [],\n",
    "    48: [11, 13, 20],\n",
    "    51: [0, 14, 31],\n",
    "}\n",
    "\n",
    "ok_channels = {\n",
    "    9: [],\n",
    "    20: [],\n",
    "    38: [14],\n",
    "    42: [],\n",
    "    48: [20],\n",
    "    51: [0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dadec40e-77f6-46c9-9690-bfa8b0876c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9a8d965550493ca8a2a975013bf4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ioff()\n",
    "plt.rcParams['font.size'] = 16\n",
    "\n",
    "root_folder = Path(r'C:\\Users\\dg\\Documents\\python\\diffusion-net\\experiments\\regression_0\\poster2025\\exported_channels')\n",
    "\n",
    "n_best = 5\n",
    "n_cp = len(pms)\n",
    "cp_grid_nr = int(np.ceil(n_cp / n_best))\n",
    "cp_grid_sz = (cp_grid_nr, n_best)\n",
    "\n",
    "\n",
    "for global_ch_idx, (model_idx, model_ch_idx) in enumerate(tqdm(cp_responses.columns, total=cp_responses.shape[1])):\n",
    "    model = sms[model_idx]\n",
    "    reader = model.reader\n",
    "    channel = reader.metadata.channel[model_ch_idx]\n",
    "    \n",
    "    expt_name = reader.trained_file.parts[2]\n",
    "    _, ga_run_id, cp_run_id = expt_name.split('_')\n",
    "    if channel not in ok_channels[int(ga_run_id)]:\n",
    "        continue\n",
    "    \n",
    "    ttl =f'{expt_name} - ch{channel}'\n",
    "    fig = plt.figure(figsize=(14, 14), constrained_layout=True)\n",
    "    # fig.suptitle(ttl, fontsize=24)\n",
    "    subfigs = fig.subfigures(5, 1, height_ratios=[2, 1, 1, 1, 1], hspace=.05)\n",
    "\n",
    "    scatter_plots(reader, channel, global_ch_idx, fig=subfigs[0], ttl=ttl)\n",
    "   \n",
    "    ga_pms, ga_vertex_weights, ga_unit_responses, ga_unit_preds = load_unit_best(model, model_ch_idx, n_best=n_best)\n",
    "    plot_single_channel_renders(ga_pms, channel_idx=model_ch_idx, grid_sz=(1, n_best), fig=subfigs[1], responses=ga_unit_responses, preds=ga_unit_preds)\n",
    "    plot_single_channel_vertex_weights(ga_pms, ga_vertex_weights, channel_idx=model_ch_idx, grid_sz=(1, n_best), fig=subfigs[2])\n",
    "\n",
    "    cp_unit_responses = cp_responses_vr.loc[:, (model_idx, model_ch_idx)].reset_index(drop=True).sort_values(ascending=False).head(n_best)\n",
    "    cp_idxs = cp_unit_responses.index.values\n",
    "    cp_pms, cp_vws = [pms[i] for i in cp_idxs], [cp_vertex_weights[i] for i in cp_idxs]\n",
    "    cp_unit_preds = cp_pm_preds.loc[[pm.index for pm in cp_pms], (model_idx, model_ch_idx)]\n",
    "    \n",
    "    plot_single_channel_renders(cp_pms, channel_idx=model_ch_idx, grid_sz=(1, n_best), fig=subfigs[3], responses=cp_unit_responses, preds=cp_unit_preds)\n",
    "    plot_single_channel_vertex_weights(cp_pms, cp_vws, channel_idx=model_ch_idx, grid_sz=(1, n_best), fig=subfigs[4])\n",
    "\n",
    "    fig.set_linewidth(10)\n",
    "    fig.savefig(root_folder / (ttl + '.png'))\n",
    "    plt.close(fig)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6627cb18-95f9-46b5-8b5f-64c720a6495a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams['font.size']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
